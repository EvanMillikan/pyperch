{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4c699e-db6d-404c-a41b-f24d4f9879cf",
   "metadata": {},
   "source": [
    "## Skorch basic classification example\n",
    "#### from skorch docs/readme - https://github.com/skorch-dev/skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4942c4-d06d-4155-a658-2d73d60dc581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Installation on Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch' , 'torch'])\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7548\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7079\u001b[0m  0.0136\n",
      "      2        \u001b[36m0.6990\u001b[0m       \u001b[32m0.5350\u001b[0m        \u001b[35m0.6864\u001b[0m  0.0193\n",
      "      3        \u001b[36m0.6823\u001b[0m       \u001b[32m0.5400\u001b[0m        \u001b[35m0.6800\u001b[0m  0.0191\n",
      "      4        \u001b[36m0.6727\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m0.6739\u001b[0m  0.0208\n",
      "      5        \u001b[36m0.6652\u001b[0m       \u001b[32m0.6000\u001b[0m        \u001b[35m0.6676\u001b[0m  0.0130\n",
      "      6        \u001b[36m0.6590\u001b[0m       \u001b[32m0.6400\u001b[0m        \u001b[35m0.6577\u001b[0m  0.0177\n",
      "      7        \u001b[36m0.6498\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6507\u001b[0m  0.0212\n",
      "      8        \u001b[36m0.6379\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.6351\u001b[0m  0.0165\n",
      "      9        \u001b[36m0.6248\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.6225\u001b[0m  0.0183\n",
      "     10        \u001b[36m0.6128\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6135\u001b[0m  0.0164\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, num_units=10, nonlin=nn.ReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")\n",
    "\n",
    "net.fit(X, y)\n",
    "y_proba = net.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40af005-0621-4017-a880-56ba295f91b6",
   "metadata": {},
   "source": [
    "## Using sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1301a1b-8a82-4c68-9172-aebbfd6cec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7128\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7006\u001b[0m  0.0215\n",
      "      2        \u001b[36m0.6963\u001b[0m       \u001b[32m0.5150\u001b[0m        \u001b[35m0.6934\u001b[0m  0.0258\n",
      "      3        \u001b[36m0.6903\u001b[0m       \u001b[32m0.5550\u001b[0m        \u001b[35m0.6901\u001b[0m  0.0225\n",
      "      4        \u001b[36m0.6873\u001b[0m       0.5500        \u001b[35m0.6885\u001b[0m  0.0216\n",
      "      5        \u001b[36m0.6857\u001b[0m       0.5500        \u001b[35m0.6868\u001b[0m  0.0261\n",
      "      6        \u001b[36m0.6830\u001b[0m       \u001b[32m0.5600\u001b[0m        \u001b[35m0.6851\u001b[0m  0.0205\n",
      "      7        \u001b[36m0.6805\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m0.6828\u001b[0m  0.0237\n",
      "      8        \u001b[36m0.6775\u001b[0m       0.5500        \u001b[35m0.6807\u001b[0m  0.0233\n",
      "      9        \u001b[36m0.6694\u001b[0m       0.5450        \u001b[35m0.6774\u001b[0m  0.0221\n",
      "     10        0.6714       0.5600        \u001b[35m0.6740\u001b[0m  0.0223\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', net),\n",
    "])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "y_proba = pipe.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca651d54-9883-49e4-9e93-82c1ec55f865",
   "metadata": {},
   "source": [
    "## Using sklearn grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d0a8dc-4b2d-4d08-9cf6-3c02c69742a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[CV] END .......lr=0.01, max_epochs=10, module__num_units=10; total time=   0.1s\n",
      "[CV] END .......lr=0.01, max_epochs=10, module__num_units=10; total time=   0.1s\n",
      "[CV] END .......lr=0.01, max_epochs=10, module__num_units=10; total time=   0.1s\n",
      "[CV] END .......lr=0.01, max_epochs=10, module__num_units=20; total time=   0.1s\n",
      "[CV] END .......lr=0.01, max_epochs=10, module__num_units=20; total time=   0.1s\n",
      "[CV] END .......lr=0.01, max_epochs=10, module__num_units=20; total time=   0.1s\n",
      "[CV] END .......lr=0.01, max_epochs=20, module__num_units=10; total time=   0.2s\n",
      "[CV] END .......lr=0.01, max_epochs=20, module__num_units=10; total time=   0.2s\n",
      "[CV] END .......lr=0.01, max_epochs=20, module__num_units=10; total time=   0.2s\n",
      "[CV] END .......lr=0.01, max_epochs=20, module__num_units=20; total time=   0.2s\n",
      "[CV] END .......lr=0.01, max_epochs=20, module__num_units=20; total time=   0.2s\n",
      "[CV] END .......lr=0.01, max_epochs=20, module__num_units=20; total time=   0.2s\n",
      "[CV] END .......lr=0.02, max_epochs=10, module__num_units=10; total time=   0.1s\n",
      "[CV] END .......lr=0.02, max_epochs=10, module__num_units=10; total time=   0.1s\n",
      "[CV] END .......lr=0.02, max_epochs=10, module__num_units=10; total time=   0.1s\n",
      "[CV] END .......lr=0.02, max_epochs=10, module__num_units=20; total time=   0.1s\n",
      "[CV] END .......lr=0.02, max_epochs=10, module__num_units=20; total time=   0.1s\n",
      "[CV] END .......lr=0.02, max_epochs=10, module__num_units=20; total time=   0.1s\n",
      "[CV] END .......lr=0.02, max_epochs=20, module__num_units=10; total time=   0.2s\n",
      "[CV] END .......lr=0.02, max_epochs=20, module__num_units=10; total time=   0.2s\n",
      "[CV] END .......lr=0.02, max_epochs=20, module__num_units=10; total time=   0.2s\n",
      "[CV] END .......lr=0.02, max_epochs=20, module__num_units=20; total time=   0.2s\n",
      "[CV] END .......lr=0.02, max_epochs=20, module__num_units=20; total time=   0.2s\n",
      "[CV] END .......lr=0.02, max_epochs=20, module__num_units=20; total time=   0.2s\n",
      "best score: 0.712, best params: {'lr': 0.02, 'max_epochs': 20, 'module__num_units': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# deactivate skorch-internal train-valid split and verbose logging\n",
    "net.set_params(train_split=False, verbose=0)\n",
    "params = {\n",
    "    'lr': [0.01, 0.02],\n",
    "    'max_epochs': [10, 20],\n",
    "    'module__num_units': [10, 20],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68076c4c-6ad7-414f-a60f-ce9bf91aaeba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyperch",
   "language": "python",
   "name": "pyperch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
